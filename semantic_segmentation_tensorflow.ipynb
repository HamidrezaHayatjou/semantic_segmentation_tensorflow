{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "####import libraries"
      ],
      "metadata": {
        "id": "n3lxUR0R8E1l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxhut2iPvmQe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import glob\n",
        "from scipy.io import loadmat\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####download,unzip dataset"
      ],
      "metadata": {
        "id": "J4K_Sfqa8JOL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**please insert USERNAME & PASSWORD to download dataset**"
      ],
      "metadata": {
        "id": "DE2yDci_DVfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --keep-session-cookies --save-cookies=cookies.txt --post-data 'username=USERNAME&password=PASSWORD&submit=Login' https://www.cityscapes-dataset.com/login/\n",
        "\n",
        "#Download leftImg8bit_trainvaltest.zip\n",
        "!wget --load-cookies cookies.txt --content-disposition https://www.cityscapes-dataset.com/file-handling/?packageID=3\n",
        "\n",
        "#gtFine_trainvaltest.zip\n",
        "!wget --load-cookies cookies.txt --content-disposition https://www.cityscapes-dataset.com/file-handling/?packageID=1\n",
        "\n",
        "!unzip \"/content/leftImg8bit_trainvaltest.zip\" -d \"/content/Cityscape/\"\n",
        "!rm -rf /content/Cityscape/README\n",
        "!rm -rf /content/Cityscape/license.txt\n",
        "\n",
        "!unzip \"/content/gtFine_trainvaltest.zip\" -d \"/content/Cityscape/\"\n",
        "!rm -rf /content/Cityscape/README\n",
        "!rm -rf /content/Cityscape/license.txt\n",
        "\n",
        "!rm -rf /content/sample_data\n",
        "!rm -rf /content/cookies.txt\n",
        "!rm -rf /content/index.html\n",
        "#!rm -rf /content/leftImg8bit_trainvaltest.zip\n",
        "#!rm -rf /content/gtFine_trainvaltest.zip"
      ],
      "metadata": {
        "id": "Fq8p8_vzwQ4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####delete useless files"
      ],
      "metadata": {
        "id": "U2W8TNWX37q3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cityscapesPath = '/content/Cityscape'\n",
        "searchFine1   = os.path.join( cityscapesPath , \"gtFine\"   , \"*\" , \"*\" , \"*_gt*_polygons.json\" )\n",
        "searchFine2   = os.path.join( cityscapesPath , \"gtFine\"   , \"*\" , \"*\" , \"*_gt*_instanceIds.png\" )\n",
        "searchFine3   = os.path.join( cityscapesPath , \"gtFine\"   , \"*\" , \"*\" , \"*_gt*_color.png\" )\n",
        "#searchFine4   = os.path.join( cityscapesPath , \"gtFine\"   , \"*\" , \"*\" , \"*_gt*_labelIds.png\" )\n",
        "\n",
        "filesFine1 = glob.glob( searchFine1 )\n",
        "filesFine2 = glob.glob( searchFine2 )\n",
        "filesFine3 = glob.glob( searchFine3 )\n",
        "#filesFine4 = glob.glob( searchFine4 )\n",
        "filesFine = filesFine1 + filesFine2 + filesFine3 #+ filesFine4\n",
        "filesFine.sort()\n",
        "#print(len(filesFine))\n",
        "\n",
        "for item in filesFine:\n",
        "    if item.endswith(\"color.png\"):\n",
        "        os.remove(item)\n",
        "    elif item.endswith(\"instanceIds.png\"):\n",
        "        os.remove(item)\n",
        "    #elif item.endswith(\"labelIds.png\"):\n",
        "    #    os.remove(item)\n",
        "    elif item.endswith(\"polygons.json\"):\n",
        "        os.remove(item)"
      ],
      "metadata": {
        "id": "uO0Laglu7N21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####read img and labels"
      ],
      "metadata": {
        "id": "atJij0Dp8l3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_h = 256\n",
        "IMAGE_w = 256\n",
        "IMAGE_SIZE = 256\n",
        "BATCH_SIZE = 4\n",
        "NUM_CLASSES = 35\n",
        "DATA_DIR = \"/content/Cityscape\"\n",
        "NUM_TRAIN_IMAGES = 2975\n",
        "NUM_VAL_IMAGES = 500\n",
        "\n",
        "train_images = sorted(glob.glob(os.path.join(DATA_DIR, \"leftImg8bit/train/*/*.png\")))\n",
        "train_masks = sorted(glob.glob(os.path.join(DATA_DIR, \"gtFine/train/*/*.png\")))\n",
        "val_images = sorted(glob.glob(os.path.join(DATA_DIR, \"leftImg8bit/val/*/*.png\")))\n",
        "val_masks = sorted(glob.glob(os.path.join(DATA_DIR, \"gtFine/val/*/*.png\")))"
      ],
      "metadata": {
        "id": "Q3_wThnw-aPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_images))\n",
        "print(len(train_masks))\n",
        "print(len(val_images))\n",
        "print(len(val_masks))"
      ],
      "metadata": {
        "id": "RLhMMpPM-yZ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "677fb5b7-8020-4493-c09d-e3506fbd00f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2975\n",
            "2975\n",
            "500\n",
            "500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_image(image_path, mask=False):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    if mask:\n",
        "        image = tf.image.decode_png(image, channels=1)\n",
        "        image.set_shape([None, None, 1])\n",
        "        image = tf.image.resize(images=image, size=[IMAGE_h, IMAGE_w])\n",
        "    else:\n",
        "        image = tf.image.decode_png(image, channels=3)\n",
        "        image.set_shape([None, None, 3])\n",
        "        image = tf.image.resize(images=image, size=[IMAGE_h, IMAGE_w])\n",
        "        image = tf.keras.applications.resnet50.preprocess_input(image)\n",
        "    return image\n",
        "\n",
        "\n",
        "def load_data(image_list, mask_list):\n",
        "    image = read_image(image_list)\n",
        "    mask = read_image(mask_list, mask=True)\n",
        "    return image, mask\n",
        "\n",
        "\n",
        "def data_generator(image_list, mask_list):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((image_list, mask_list))\n",
        "    dataset = dataset.map(load_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "train_dataset = data_generator(train_images, train_masks)\n",
        "val_dataset = data_generator(val_images, val_masks)\n",
        "\n",
        "print(\"Train Dataset:\", train_dataset)\n",
        "print(\"Val Dataset:\", val_dataset)\n"
      ],
      "metadata": {
        "id": "mcTJ6zwFyvkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####define network"
      ],
      "metadata": {
        "id": "F7GuNvMQ4k2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convolution_block(\n",
        "    block_input,\n",
        "    num_filters=256,\n",
        "    kernel_size=3,\n",
        "    dilation_rate=1,\n",
        "    padding=\"same\",\n",
        "    use_bias=False,\n",
        "):\n",
        "    x = layers.Conv2D(\n",
        "        num_filters,\n",
        "        kernel_size=kernel_size,\n",
        "        dilation_rate=dilation_rate,\n",
        "        padding=\"same\",\n",
        "        use_bias=use_bias,\n",
        "        kernel_initializer=keras.initializers.HeNormal(),\n",
        "    )(block_input)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    return tf.nn.relu(x)\n",
        "\n",
        "\n",
        "def DilatedSpatialPyramidPooling(dspp_input):\n",
        "    dims = dspp_input.shape\n",
        "    x = layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)\n",
        "    x = convolution_block(x, kernel_size=1, use_bias=True)\n",
        "    out_pool = layers.UpSampling2D(\n",
        "        size=(dims[-3] // x.shape[1], dims[-2] // x.shape[2]), interpolation=\"bilinear\",\n",
        "    )(x)\n",
        "\n",
        "    out_1 = convolution_block(dspp_input, kernel_size=1, dilation_rate=1)\n",
        "    out_6 = convolution_block(dspp_input, kernel_size=3, dilation_rate=6)\n",
        "    out_12 = convolution_block(dspp_input, kernel_size=3, dilation_rate=12)\n",
        "    out_18 = convolution_block(dspp_input, kernel_size=3, dilation_rate=18)\n",
        "\n",
        "    x = layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])\n",
        "    output = convolution_block(x, kernel_size=1)\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "pfr0jtheB65Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def DeeplabV3Plus(image_size, num_classes):\n",
        "    model_input = keras.Input(shape=(image_size, image_size, 3))\n",
        "    resnet50 = keras.applications.ResNet50(\n",
        "        weights=\"imagenet\", include_top=False, input_tensor=model_input\n",
        "    )\n",
        "    x = resnet50.get_layer(\"conv4_block6_2_relu\").output\n",
        "    x = DilatedSpatialPyramidPooling(x)\n",
        "\n",
        "    input_a = layers.UpSampling2D(\n",
        "        size=(image_size // 4 // x.shape[1], image_size // 4 // x.shape[2]),\n",
        "        interpolation=\"bilinear\",\n",
        "    )(x)\n",
        "    input_b = resnet50.get_layer(\"conv2_block3_2_relu\").output\n",
        "    input_b = convolution_block(input_b, num_filters=48, kernel_size=1)\n",
        "\n",
        "    x = layers.Concatenate(axis=-1)([input_a, input_b])\n",
        "    x = convolution_block(x)\n",
        "    x = convolution_block(x)\n",
        "    x = layers.UpSampling2D(\n",
        "        size=(image_size // x.shape[1], image_size // x.shape[2]),\n",
        "        interpolation=\"bilinear\",\n",
        "    )(x)\n",
        "    model_output = layers.Conv2D(num_classes, kernel_size=(1, 1), padding=\"same\")(x)\n",
        "    return keras.Model(inputs=model_input, outputs=model_output)\n",
        "\n",
        "\n",
        "model = DeeplabV3Plus(image_size=IMAGE_SIZE, num_classes=NUM_CLASSES)\n",
        "#model.summary()\n"
      ],
      "metadata": {
        "id": "WOctcreQB-0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####compile and train"
      ],
      "metadata": {
        "id": "DK9CnwiB4qzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=loss,\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "gMwGur0EDLwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_dataset, validation_data=val_dataset, epochs=25)"
      ],
      "metadata": {
        "id": "PLsCzbDM21Cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####save and Load"
      ],
      "metadata": {
        "id": "zukL3Hhe4uVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"model.h5\")"
      ],
      "metadata": {
        "id": "Wrou6wsCxq79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = '/content/model.h5'\n",
        "model1 = tf.keras.models.load_model(\n",
        "    filepath, custom_objects=None, compile=True, options=None\n",
        "    )"
      ],
      "metadata": {
        "id": "RX3NSd-Wxrd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Drawing curves"
      ],
      "metadata": {
        "id": "l8Auvbp54zQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history[\"loss\"])\n",
        "plt.title(\"Training Loss\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history[\"accuracy\"])\n",
        "plt.title(\"Training Accuracy\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history[\"val_loss\"])\n",
        "plt.title(\"Validation Loss\")\n",
        "plt.ylabel(\"val_loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history[\"val_accuracy\"])\n",
        "plt.title(\"Validation Accuracy\")\n",
        "plt.ylabel(\"val_accuracy\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "4tIZAKcjDIq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####predictions"
      ],
      "metadata": {
        "id": "KpnW8b0S5Ocd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the Colormap\n",
        "\n",
        "import numpy as np\n",
        "colormap = [\n",
        "    [128,  64, 128], [244,  35, 232], [70,  70,  70 ], [102, 102, 156], [190, 153, 153],\n",
        "    [153, 153, 153], [250, 170,  30], [220, 220,   0], [107, 142,  35], [152, 251, 152],\n",
        "    [ 70, 130, 180], [220,  20,  60], [255,   0,   0], [0,   0, 142  ], [0,   0,  70  ],\n",
        "    [0,  60, 100  ], [0,  80, 100  ], [0,   0, 230  ], [119,  11,  32], [128,  64, 128],\n",
        "    [244,  35, 232], [70,  70,  70 ], [102, 102, 156], [190, 153, 153], [153, 153, 153],\n",
        "    [250, 170,  30], [220, 220,   0], [107, 142,  35], [152, 251, 152], [70, 130, 180 ],\n",
        "    [220,  20,  60], [255,   0,   0], [0,   0, 142  ], [0,   0,  70  ], [0,  60, 100  ]]"
      ],
      "metadata": {
        "id": "RaLItG9W06gB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def infer(model, image_tensor):\n",
        "    predictions = model.predict(np.expand_dims((image_tensor), axis=0))\n",
        "    predictions = np.squeeze(predictions)\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "    return predictions\n",
        "\n",
        "\n",
        "def decode_segmentation_masks(mask, colormap, n_classes):\n",
        "    r = np.zeros_like(mask).astype(np.uint8)\n",
        "    g = np.zeros_like(mask).astype(np.uint8)\n",
        "    b = np.zeros_like(mask).astype(np.uint8)\n",
        "    for l in range(0, n_classes):\n",
        "        idx = mask == l\n",
        "        colormp = colormap[l]\n",
        "        r[idx] = colormp[0]\n",
        "        g[idx] = colormp[1]\n",
        "        b[idx] = colormp[2]\n",
        "    rgb = np.stack([r, g, b], axis=2)\n",
        "    return rgb\n",
        "\n",
        "\n",
        "def get_overlay(image, colored_mask):\n",
        "    image = tf.keras.utils.array_to_img(image)\n",
        "    image = np.array(image).astype(np.uint8)\n",
        "    overlay = cv2.addWeighted(image, 0.35, colored_mask, 0.65, 0)\n",
        "    return overlay\n",
        "\n",
        "\n",
        "def plot_samples_matplotlib(display_list, figsize=(5, 3)):\n",
        "    _, axes = plt.subplots(nrows=1, ncols=len(display_list), figsize=figsize)\n",
        "    for i in range(len(display_list)):\n",
        "        if display_list[i].shape[-1] == 3:\n",
        "            axes[i].imshow(tf.keras.utils.array_to_img(display_list[i]))\n",
        "        else:\n",
        "            axes[i].imshow(display_list[i])\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_predictions(images_list, colormap, model):\n",
        "    for image_file in images_list:\n",
        "        image_tensor = read_image(image_file)\n",
        "        prediction_mask = infer(image_tensor=image_tensor, model=model)\n",
        "        prediction_colormap = decode_segmentation_masks(prediction_mask, colormap, 20)\n",
        "        overlay = get_overlay(image_tensor, prediction_colormap)\n",
        "        plot_samples_matplotlib(\n",
        "            [image_tensor, overlay, prediction_colormap], figsize=(18, 14)\n",
        "        )"
      ],
      "metadata": {
        "id": "dCLkol8ryTa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions(train_images[:4], colormap, model=model)"
      ],
      "metadata": {
        "id": "176obdVFyxas"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}